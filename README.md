# Advanced RAG System

Upload documents and ask AI questions about them with source citations.

## ðŸ—ï¸ Architecture

```mermaid
graph TB
    User[ðŸ‘¤ User] --> WebUI[ðŸŒ React Frontend]
    WebUI --> API[ðŸ”Œ FastAPI Backend]
    API --> Processor[ðŸ“ Document Processor]
    API --> QueryEngine[ðŸ” Query Engine]
    
    Processor --> Embeddings[ðŸ§  OpenAI Embeddings]
    Embeddings --> VectorDB[(ðŸ—„ï¸ Qdrant Vector DB)]
    
    QueryEngine --> VectorDB
    QueryEngine --> LLM[ðŸ¤– GPT-4]
    
    API --> PostgreSQL[(ðŸ’¾ PostgreSQL)]
    API --> Redis[(âš¡ Redis Cache)]
```

## ðŸš€ Quick Start

```bash
# Clone and setup
git clone <repository-url>
cd ai-rag-python
cp .env.example .env
# Edit .env with your OpenAI API key

# Start services
docker-compose up -d

# Access
# Frontend: http://localhost:3000
# API Docs: http://localhost:8000/docs
```

## ðŸ”§ Development

**Backend:**
```bash
cd backend && pip install -r requirements.txt
uvicorn app.main:app --reload
```

**Frontend:**
```bash
cd frontend && npm install
npm start
```

## ðŸ“‹ Key Features

- Multi-format document support (PDF, text)
- AI-powered Q&A with citations
- Semantic search via vector embeddings
- React frontend + FastAPI backend
- Production Docker deployment